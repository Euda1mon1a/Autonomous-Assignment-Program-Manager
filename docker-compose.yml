# Production Docker Compose Configuration
# For development, use: docker-compose -f docker-compose.yml -f docker-compose.dev.yml up

services:
  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: residency-scheduler-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: scheduler
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: residency_scheduler
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scheduler -d residency_scheduler"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - app-network

  # Redis - Message Broker for Celery
  redis:
    image: redis:7-alpine
    container_name: residency-scheduler-redis
    restart: unless-stopped
    # Port removed for production security - Redis only accessible within Docker network
    # For local development, use docker-compose.dev.yml to expose port
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-dev_only_password}
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-dev_only_password}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-dev_only_password}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
      - app-network

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: residency-scheduler-backend
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://scheduler:${DB_PASSWORD}@db:5432/residency_scheduler
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dev_only_password}
      REDIS_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: "false"
      CORS_ORIGINS: ${CORS_ORIGINS:-["http://localhost:3000"]}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-false}
    ports:
      - "8000:8000"
    networks:
      - app-network

  # Celery Worker
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: residency-scheduler-celery-worker
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://scheduler:${DB_PASSWORD}@db:5432/residency_scheduler
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dev_only_password}
      REDIS_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: "false"
    command: celery -A app.core.celery_app worker --loglevel=info -Q default,resilience,notifications
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery_app inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Celery Beat Scheduler
  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: residency-scheduler-celery-beat
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://scheduler:${DB_PASSWORD}@db:5432/residency_scheduler
      REDIS_PASSWORD: ${REDIS_PASSWORD:-dev_only_password}
      REDIS_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: "false"
    command: celery -A app.core.celery_app beat --loglevel=info
    networks:
      - app-network

  # Next.js Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: residency-scheduler-frontend
    restart: unless-stopped
    depends_on:
      - backend
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:8000}
    ports:
      - "3000:3000"
    networks:
      - app-network

  # MCP Server - Model Context Protocol for AI Assistant Integration
  # Provides 29+ specialized scheduling tools for Claude Code and other AI agents
  # Security model follows Docker MCP Toolkit patterns (resource limits, privilege dropping)
  mcp-server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    container_name: residency-scheduler-mcp
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # API Integration - connects to FastAPI backend (not direct DB)
      API_BASE_URL: http://backend:8000
      # Celery for async task management
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD:-dev_only_password}@redis:6379/0
      # Logging
      LOG_LEVEL: ${MCP_LOG_LEVEL:-INFO}
      # Python path for imports
      PYTHONPATH: /app/src
    # Security constraints (Docker MCP Toolkit pattern)
    # - Resource limits prevent runaway processes
    # - no-new-privileges prevents privilege escalation
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 256M
    # No ports exposed by default - stdio transport via docker exec
    # For HTTP transport, uncomment: ports: ["8080:8080"]
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "python", "-c", "from scheduler_mcp.server import mcp; print('healthy')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # n8n - Workflow Automation
  n8n:
    image: n8nio/n8n
    container_name: residency-scheduler-n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER:-admin}
      # SECURITY: N8N_PASSWORD must be set in .env file - no default provided for security
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5678}
      - GENERIC_TIMEZONE=America/New_York
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - app-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  n8n_data:
    driver: local

networks:
  app-network:
    driver: bridge
