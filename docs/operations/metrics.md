# Prometheus Metrics Documentation

This document provides a comprehensive reference for all Prometheus metrics exposed by the Residency Scheduler application.

## Table of Contents

- [Overview](#overview)
- [Accessing Metrics](#accessing-metrics)
- [Metric Categories](#metric-categories)
  - [HTTP Metrics (FastAPI)](#http-metrics-fastapi)
  - [Resilience Metrics](#resilience-metrics)
  - [Scheduling Metrics](#scheduling-metrics)
  - [ACGME Compliance Metrics](#acgme-compliance-metrics)
  - [Infrastructure Metrics](#infrastructure-metrics)
- [Example PromQL Queries](#example-promql-queries)
- [Grafana Dashboard Recommendations](#grafana-dashboard-recommendations)
- [Alert Threshold Recommendations](#alert-threshold-recommendations)

## Overview

The Residency Scheduler application exposes metrics at the `/metrics` endpoint using the Prometheus exposition format. Metrics are automatically collected and visualized in Grafana dashboards.

**Key Points:**
- Metrics endpoint: `http://backend:8000/metrics`
- Default scrape interval: 15 seconds
- Metrics are restricted to internal networks in production
- Uses `prometheus-fastapi-instrumentator` for HTTP metrics
- Custom metrics for resilience and compliance monitoring

## Accessing Metrics

### Development Environment
```bash
curl http://localhost:8000/metrics
```

### Production Environment
The `/metrics` endpoint is restricted to internal networks (127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) in production mode.

## Metric Categories

### HTTP Metrics (FastAPI)

These metrics are automatically generated by `prometheus-fastapi-instrumentator`.

#### `http_requests_total`
**Type:** Counter
**Description:** Total number of HTTP requests received
**Labels:**
- `method` - HTTP method (GET, POST, PUT, DELETE, etc.)
- `handler` - FastAPI route handler path
- `status` - HTTP status code (200, 404, 500, etc.)

**Example:**
```promql
# Request rate by endpoint
rate(http_requests_total{job="residency-scheduler-backend"}[5m])

# Total 5xx errors
sum(rate(http_requests_total{status=~"5.."}[5m]))
```

---

#### `http_request_duration_seconds`
**Type:** Histogram
**Description:** HTTP request duration in seconds
**Labels:**
- `method` - HTTP method
- `handler` - FastAPI route handler path
- `le` - Histogram bucket upper bound

**Buckets:** Auto-generated by instrumentator (typically 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)

**Example:**
```promql
# P95 latency by endpoint
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, handler)
)

# P99 latency overall
histogram_quantile(0.99,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

---

#### `http_requests_inprogress`
**Type:** Gauge
**Description:** Number of HTTP requests currently being processed
**Labels:**
- `method` - HTTP method
- `handler` - FastAPI route handler path

**Example:**
```promql
# Current in-flight requests
sum(http_requests_inprogress{job="residency-scheduler-backend"})
```

---

### Resilience Metrics

Custom metrics for monitoring system resilience and operational health.

#### Gauges

#### `resilience_utilization_rate`
**Type:** Gauge
**Description:** Current system utilization rate (0.0-1.0)
**Labels:**
- `component` - Component name (overall, faculty, rotation, etc.)

**Interpretation:**
- 0.0-0.7 (GREEN): Normal operations
- 0.7-0.85 (YELLOW): Elevated utilization
- 0.85-0.95 (ORANGE): High utilization
- 0.95-1.0 (RED): Critical utilization
- 1.0+ (BLACK): Overutilization

**Example:**
```promql
# Overall utilization
resilience_utilization_rate{component="overall"}

# Alert when utilization high
resilience_utilization_rate > 0.85
```

---

#### `resilience_utilization_level`
**Type:** Gauge
**Description:** Current utilization level as integer (0=GREEN, 1=YELLOW, 2=ORANGE, 3=RED, 4=BLACK)

**Example:**
```promql
# Count systems in each level
count(resilience_utilization_level) by (level)

# Alert on RED or BLACK
resilience_utilization_level >= 3
```

---

#### `resilience_defense_level`
**Type:** Gauge
**Description:** Active defense-in-depth level (1-5)
**Levels:**
1. Prevention - Proactive measures
2. Detection - Monitoring and alerts
3. Mitigation - Load balancing and optimization
4. Recovery - Fallback activation
5. Emergency - Crisis response

**Example:**
```promql
# Current defense level
resilience_defense_level

# Alert when emergency level activated
resilience_defense_level >= 5
```

---

#### `resilience_load_shedding_level`
**Type:** Gauge
**Description:** Current load shedding level (0=NORMAL to 5=CRITICAL)
**Levels:**
- 0: NORMAL - All services operational
- 1: LOW - Minor non-essential services suspended
- 2: MODERATE - Additional services suspended
- 3: HIGH - Only essential services
- 4: SEVERE - Minimal services
- 5: CRITICAL - Emergency mode

**Example:**
```promql
# Alert on load shedding activation
resilience_load_shedding_level > 0
```

---

#### `resilience_n1_compliant`
**Type:** Gauge
**Description:** Whether system passes N-1 contingency analysis (1=pass, 0=fail)
**Meaning:** System can handle loss of any single faculty member

**Example:**
```promql
# Alert on N-1 failure
resilience_n1_compliant == 0
```

---

#### `resilience_n2_compliant`
**Type:** Gauge
**Description:** Whether system passes N-2 contingency analysis (1=pass, 0=fail)
**Meaning:** System can handle simultaneous loss of any two faculty members

**Example:**
```promql
# Alert on N-2 failure
resilience_n2_compliant == 0
```

---

#### `resilience_faculty_available`
**Type:** Gauge
**Description:** Number of available faculty members
**Labels:**
- `type` - Faculty type (total, on_duty, on_leave)

**Example:**
```promql
# Total available faculty
resilience_faculty_available{type="total"}

<<<<<<< HEAD
# Faculty on duty
=======
***REMOVED*** on duty
>>>>>>> origin/docs/session-14-summary
resilience_faculty_available{type="on_duty"}

# Alert when faculty count drops
resilience_faculty_available{type="total"} < 10
```

---

#### `resilience_coverage_rate`
**Type:** Gauge
**Description:** Current schedule coverage rate (0.0-1.0)
**Target:** >= 0.95 (95% coverage)

**Example:**
```promql
# Current coverage
resilience_coverage_rate

# Alert on low coverage
resilience_coverage_rate < 0.95
```

---

#### `resilience_buffer_remaining`
**Type:** Gauge
**Description:** Remaining capacity buffer before threshold (0.0-1.0)

**Example:**
```promql
# Buffer exhaustion warning
resilience_buffer_remaining < 0.2
```

---

#### `resilience_redundancy_level`
**Type:** Gauge
**Description:** Redundancy level for critical services (0=BELOW, 1=N+0, 2=N+1, 3=N+2)
**Labels:**
- `service` - Service name

**Example:**
```promql
# Services with insufficient redundancy
resilience_redundancy_level{service=~".*"} < 2
```

---

#### `resilience_active_fallbacks`
**Type:** Gauge
**Description:** Number of currently active fallback schedules

**Example:**
```promql
# Alert when fallbacks activated
resilience_active_fallbacks > 0
```

---

#### `resilience_suspended_activities`
**Type:** Gauge
**Description:** Number of currently suspended activities due to load shedding

**Example:**
```promql
# Monitor suspended activities
resilience_suspended_activities
```

---

#### Counters

#### `resilience_crisis_activations_total`
**Type:** Counter
**Description:** Total number of crisis response activations
**Labels:**
- `severity` - Crisis severity (minor, moderate, severe, critical)

**Example:**
```promql
# Crisis activation rate
rate(resilience_crisis_activations_total[1h])

# Critical crises in last 24h
increase(resilience_crisis_activations_total{severity="critical"}[24h])
```

---

#### `resilience_fallback_activations_total`
**Type:** Counter
**Description:** Total number of fallback schedule activations
**Labels:**
- `scenario` - Fallback scenario name

**Example:**
```promql
# Fallback activation rate
rate(resilience_fallback_activations_total[1h])

# Most common fallback scenarios
topk(5, increase(resilience_fallback_activations_total[7d]))
```

---

#### `resilience_load_shedding_events_total`
**Type:** Counter
**Description:** Total number of load shedding level changes
**Labels:**
- `from_level` - Previous load shedding level
- `to_level` - New load shedding level

**Example:**
```promql
# Load shedding escalations
rate(resilience_load_shedding_events_total{to_level=~"[3-5]"}[1h])
```

---

#### `resilience_defense_activations_total`
**Type:** Counter
**Description:** Total number of defense action activations
**Labels:**
- `level` - Defense level (1-5)
- `action` - Action taken

**Example:**
```promql
# Defense activations by level
sum(rate(resilience_defense_activations_total[1h])) by (level)
```

---

#### `resilience_health_check_failures_total`
**Type:** Counter
**Description:** Total number of failed health checks
**Labels:**
- `reason` - Failure reason

**Example:**
```promql
# Health check failure rate
rate(resilience_health_check_failures_total[5m])

# Failures by reason
topk(3, increase(resilience_health_check_failures_total[1h])) by (reason)
```

---

#### Histograms

#### `resilience_health_check_duration_seconds`
**Type:** Histogram
**Description:** Duration of health check operations in seconds
**Buckets:** [0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]

**Example:**
```promql
# P95 health check duration
histogram_quantile(0.95,
  sum(rate(resilience_health_check_duration_seconds_bucket[5m])) by (le)
)

# Slow health checks
histogram_quantile(0.99,
  rate(resilience_health_check_duration_seconds_bucket[5m])
) > 5
```

---

#### `resilience_contingency_analysis_duration_seconds`
**Type:** Histogram
**Description:** Duration of N-1/N-2 contingency analysis in seconds
**Buckets:** [0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0]

**Example:**
```promql
# Average analysis time
rate(resilience_contingency_analysis_duration_seconds_sum[5m]) /
rate(resilience_contingency_analysis_duration_seconds_count[5m])
```

---

#### Info

#### `resilience_info`
**Type:** Info
**Description:** Resilience framework version and configuration information
**Labels:**
- `version` - Framework version
- `framework` - Framework type
- `components` - Active components

---

### Scheduling Metrics

Metrics related to schedule generation and optimization.

#### `schedule_generation_total`
**Type:** Counter
**Description:** Total number of schedule generation attempts
**Labels:**
- `status` - Generation status (success, failure)
- `type` - Schedule type (primary, fallback)

**Example:**
```promql
# Schedule generation rate
rate(schedule_generation_total[1h])

# Success rate
sum(rate(schedule_generation_total{status="success"}[1h])) /
sum(rate(schedule_generation_total[1h]))
```

---

#### `schedule_generation_failures_total`
**Type:** Counter
**Description:** Total number of schedule generation failures
**Labels:**
- `reason` - Failure reason

**Example:**
```promql
# Recent failures
increase(schedule_generation_failures_total[1h])

# Failure rate by reason
topk(5, rate(schedule_generation_failures_total[1h])) by (reason)
```

---

#### `schedule_generation_duration_seconds`
**Type:** Histogram
**Description:** Schedule generation duration in seconds
**Labels:**
- `quantile` - Percentile (0.5, 0.95, 0.99)

**Example:**
```promql
# P95 generation time
schedule_generation_duration_seconds{quantile="0.95"}

# Alert on slow generation
schedule_generation_duration_seconds{quantile="0.95"} > 300
```

---

### ACGME Compliance Metrics

Metrics for monitoring ACGME work hour and program requirement compliance.

#### `acgme_compliance_violations_total`
**Type:** Counter
**Description:** Total ACGME compliance violations detected
**Labels:**
- `regulation` - ACGME regulation code (e.g., VI.F.1, VI.F.3)
- `severity` - Violation severity (warning, critical)
- `resident_id` - Affected resident (when applicable)

**Example:**
```promql
# Violations in last 24h
increase(acgme_compliance_violations_total[24h])

# Violations by regulation
sum(rate(acgme_compliance_violations_total[1d])) by (regulation)
```

---

#### `acgme_violations_total`
**Type:** Counter
**Description:** Aggregate count of all ACGME violations

**Example:**
```promql
# Daily violation rate
increase(acgme_violations_total[24h])

# Alert on violation spike
increase(acgme_violations_total[1h]) > 5
```

---

#### `acgme_compliance_score_gauge`
**Type:** Gauge
**Description:** Overall program ACGME compliance score (0.0-1.0)
**Target:** >= 0.95 (95% compliance)

**Example:**
```promql
# Current compliance score
acgme_compliance_score_gauge

# Alert on low compliance
acgme_compliance_score_gauge < 0.90
```

---

#### Work Hour Metrics

#### `resident_weekly_hours_gauge`
**Type:** Gauge
**Description:** Current week hours for each resident
**Labels:**
- `resident_id` - Resident identifier
- `pgy_level` - Post-graduate year level

**Threshold:** 80 hours per week (ACGME VI.F.1)

**Example:**
```promql
# Residents approaching limit
resident_weekly_hours_gauge > 72

# Average weekly hours
avg(resident_weekly_hours_gauge)
```

---

#### `resident_4week_avg_hours_gauge`
**Type:** Gauge
**Description:** 4-week average hours for each resident
**Labels:**
- `resident_id` - Resident identifier

**Threshold:** 80 hours (averaged over 4 weeks)

**Example:**
```promql
# 4-week average violations
resident_4week_avg_hours_gauge > 80
```

---

#### `resident_continuous_hours_gauge`
**Type:** Gauge
**Description:** Current continuous duty hours for residents on shift
**Labels:**
- `resident_id` - Resident identifier

**Threshold:** 24 hours (+3 hours for transition)

**Example:**
```promql
# Residents on extended shifts
resident_continuous_hours_gauge > 20

# Critical duty hour violations
resident_continuous_hours_gauge > 27
```

---

#### Rest and Recovery Metrics

#### `resident_days_since_day_off_gauge`
**Type:** Gauge
**Description:** Days since last day off for each resident
**Labels:**
- `resident_id` - Resident identifier

**Threshold:** 7 days (1 day off per 7 days)

**Example:**
```promql
# Residents needing day off
resident_days_since_day_off_gauge >= 6

# Violations
resident_days_since_day_off_gauge > 7
```

---

#### `resident_4week_days_off_gauge`
**Type:** Gauge
**Description:** Total days off in last 4 weeks for each resident
**Labels:**
- `resident_id` - Resident identifier

**Threshold:** Minimum 4 days off per 4 weeks

**Example:**
```promql
# Insufficient rest
resident_4week_days_off_gauge < 4
```

---

#### Night Float Metrics

#### `resident_consecutive_night_float_gauge`
**Type:** Gauge
**Description:** Consecutive nights of night float for residents
**Labels:**
- `resident_id` - Resident identifier

**Threshold:** Maximum 6 consecutive nights

**Example:**
```promql
# Night float limit approaching
resident_consecutive_night_float_gauge >= 5

# Violations
resident_consecutive_night_float_gauge > 6
```

---

#### Supervision Metrics

#### `pgy1_unsupervised_procedures_total`
**Type:** Counter
**Description:** Count of procedures performed by PGY-1 residents without supervision
**Labels:**
- `resident_id` - Resident identifier
- `procedure_type` - Type of procedure

**Threshold:** 0 (all PGY-1 procedures require supervision)

**Example:**
```promql
# PGY-1 supervision violations
pgy1_unsupervised_procedures_total > 0

# Violations by procedure type
sum(pgy1_unsupervised_procedures_total) by (procedure_type)
```

---

#### `scheduled_blocks_without_faculty_gauge`
**Type:** Gauge
**Description:** Number of scheduled blocks lacking required faculty coverage

**Threshold:** 0 (all blocks should have faculty coverage)

**Example:**
```promql
<<<<<<< HEAD
# Faculty coverage gaps
=======
***REMOVED*** coverage gaps
>>>>>>> origin/docs/session-14-summary
scheduled_blocks_without_faculty_gauge > 0
```

---

### Infrastructure Metrics

Standard infrastructure metrics collected from various exporters.

#### Node Exporter Metrics
- `node_cpu_seconds_total` - CPU time by mode
- `node_memory_MemTotal_bytes` - Total memory
- `node_memory_MemAvailable_bytes` - Available memory
- `node_filesystem_size_bytes` - Filesystem size
- `node_filesystem_avail_bytes` - Available disk space
- `node_network_receive_bytes_total` - Network bytes received
- `node_network_transmit_bytes_total` - Network bytes transmitted

#### PostgreSQL Metrics (postgres_exporter)
- `pg_up` - Database availability (1=up, 0=down)
- `pg_stat_activity_count` - Active connections
- `pg_stat_database_deadlocks` - Deadlock count
- `pg_stat_activity_max_tx_duration` - Longest transaction duration
- `pg_replication_lag` - Replication lag in seconds

#### Container Metrics (cAdvisor)
- `container_cpu_usage_seconds_total` - Container CPU usage
- `container_memory_usage_bytes` - Container memory usage
- `container_restart_count` - Container restart count
- `container_start_time_seconds` - Container start time

---

## Example PromQL Queries

### Application Performance

```promql
# Request rate (requests per second)
sum(rate(http_requests_total{job="residency-scheduler-backend"}[5m]))

# Error rate percentage
(
  sum(rate(http_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_requests_total[5m]))
) * 100

# P50, P95, P99 latency
histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

# Top 5 slowest endpoints (by P95)
topk(5,
  histogram_quantile(0.95,
    sum(rate(http_request_duration_seconds_bucket[5m])) by (le, handler)
  )
)

# Request rate by endpoint
sum(rate(http_requests_total[5m])) by (handler)
```

### Resilience Monitoring

```promql
# System under stress
resilience_utilization_level >= 2  # ORANGE or higher

# Crisis mode active
resilience_defense_level >= 4  # Recovery or Emergency

# Contingency failures
resilience_n1_compliant == 0 or resilience_n2_compliant == 0

# Crisis activation rate
rate(resilience_crisis_activations_total[1h])

# Load shedding active
resilience_load_shedding_level > 0

<<<<<<< HEAD
# Faculty shortage
=======
***REMOVED*** shortage
>>>>>>> origin/docs/session-14-summary
resilience_faculty_available{type="total"} < 15
```

### ACGME Compliance

```promql
# Overall compliance score
acgme_compliance_score_gauge

# Residents over 72 hours this week (warning threshold)
count(resident_weekly_hours_gauge > 72)

# Residents violating 80-hour limit
count(resident_weekly_hours_gauge > 80)

# Residents on extended continuous duty
count(resident_continuous_hours_gauge > 20)

# Residents needing days off
count(resident_days_since_day_off_gauge >= 6)

# Night float violations
count(resident_consecutive_night_float_gauge > 6)

# Daily violation trend
increase(acgme_violations_total[24h])

# Violations by regulation type
sum(increase(acgme_compliance_violations_total[24h])) by (regulation)
```

### Schedule Generation

```promql
# Schedule generation success rate
(
  sum(rate(schedule_generation_total{status="success"}[1h]))
  /
  sum(rate(schedule_generation_total[1h]))
) * 100

# Recent generation failures
increase(schedule_generation_failures_total[1h])

# Average generation time
avg(schedule_generation_duration_seconds{quantile="0.50"})

# Slow schedule generations
schedule_generation_duration_seconds{quantile="0.95"} > 180
```

### System Health

```promql
# CPU usage percentage
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Memory usage percentage
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# Disk space available percentage
(node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100

# Database connections
pg_stat_activity_count

# Database availability
pg_up

# Container restart rate
rate(container_restart_count[1h])
```

---

## Grafana Dashboard Recommendations

### 1. Overview Dashboard

**Purpose:** High-level system health at a glance

**Panels:**
- **Service Status** (Stat panels)
  - Backend API up/down: `up{job="residency-scheduler-backend"}`
  - Database up/down: `pg_up`
  - Active alerts: `ALERTS{alertstate="firing"}`

- **Request Rate** (Time series)
  - Total RPS: `sum(rate(http_requests_total[5m]))`
  - Success/Error breakdown by status code

- **Response Time** (Time series)
  - P50, P95, P99 latency over time

- **Resilience Status** (Gauge/Stat)
  - Utilization level
  - Defense level
  - N-1/N-2 compliance

- **ACGME Compliance** (Stat/Gauge)
  - Overall compliance score
  - Active violations count

### 2. Application Performance Dashboard

**Panels:**
- **Request Rate by Endpoint** (Bar chart)
- **Latency Heatmap** (Heatmap)
- **Error Rate by Endpoint** (Table)
- **In-flight Requests** (Time series)
- **Schedule Generation Stats** (Mixed)
  - Generation time trend
  - Success/failure rate
  - Failures by reason

### 3. ACGME Compliance Dashboard

**Panels:**
- **Compliance Score Trend** (Time series)
- **Work Hour Distribution** (Histogram)
  - Current weekly hours per resident
- **Residents by Hours Bracket** (Pie chart)
  - <60h, 60-72h, 72-80h, >80h
- **Continuous Duty Status** (Table)
  - Current shift hours for on-duty residents
- **Days Off Compliance** (Bar gauge)
  - Days since last day off per resident
- **Night Float Status** (Table)
  - Consecutive night float nights
- **Violation Summary** (Stat panels)
  - Total violations last 24h
  - Violations by type
- **Violation Timeline** (Time series)
  - Violations over time by regulation

### 4. Resilience Monitoring Dashboard

**Panels:**
- **Utilization Trends** (Time series)
  - Overall utilization rate
  - By component
- **Defense Level History** (Time series)
- **Contingency Analysis** (Stat)
  - N-1 status
  - N-2 status
- **Faculty Availability** (Gauge)
  - Total, on-duty, on-leave
- **Crisis Events** (Time series)
  - Activations by severity
- **Fallback Activations** (Table)
  - Recent fallback scenarios
- **Load Shedding Status** (Stat)
  - Current level
  - Suspended activities

### 5. Infrastructure Dashboard

**Panels:**
- **CPU Usage** (Time series)
- **Memory Usage** (Time series)
- **Disk Space** (Bar gauge)
- **Network Traffic** (Time series)
- **Database Connections** (Time series)
- **Container Health** (Table)
  - Restart counts
  - Resource usage

---

## Alert Threshold Recommendations

### Critical Alerts (Immediate Response)

| Alert | Threshold | Duration | Priority |
|-------|-----------|----------|----------|
| API Service Down | `up == 0` | 1m | P1 |
| Database Down | `pg_up == 0` | 1m | P1 |
| Critical Error Rate | Error rate > 15% | 2m | P1 |
| ACGME Work Hour Violation | Hours > 80 | 0m | P1 |
| ACGME Continuous Duty Violation | Hours > 27 | 0m | P1 |
| Compliance Score Critical | Score < 0.90 | 30m | P1 |
| CPU Critical | Usage > 95% | 5m | P1 |
| Memory Critical | Usage > 95% | 5m | P1 |
| Disk Space Critical | Available < 10% | 2m | P1 |
| N-1 Contingency Failure | `resilience_n1_compliant == 0` | 5m | P1 |

### Warning Alerts (30-Minute Response)

| Alert | Threshold | Duration | Priority |
|-------|-----------|----------|----------|
| High Error Rate | Error rate > 5% | 5m | P2 |
| High Latency P95 | P95 > 2s | 5m | P2 |
| ACGME Work Hour Warning | Hours > 72 | 0m | P2 |
| ACGME Day Off Warning | Days without rest >= 6 | 0m | P2 |
| Night Float Warning | Consecutive nights >= 5 | 0m | P2 |
| Compliance Score Low | Score < 0.95 | 1h | P2 |
| Schedule Generation Failures | Failures > 5/hour | 0m | P2 |
| High CPU | Usage > 80% | 10m | P2 |
| High Memory | Usage > 80% | 10m | P2 |
| Disk Space Warning | Available < 20% | 5m | P2 |
| Utilization High | Level >= 2 (ORANGE) | 10m | P2 |
| Faculty Coverage Gap | Gaps > 0 | 5m | P2 |

### Info Alerts (Best Effort)

| Alert | Threshold | Duration | Priority |
|-------|-----------|----------|----------|
| No Schedules Generated | No generation in 24h | 0m | P3 |
| ACGME Daily Summary | Any violations in 24h | 0m | P3 |
| Defense Level Elevated | Level >= 3 | 0m | P3 |
| Load Shedding Active | Level > 0 | 0m | P3 |
| Fallback Activated | Active fallbacks > 0 | 0m | P3 |

### Notification Routing

**Critical (P1):**
- PagerDuty: Immediate page
- Slack: #alerts-critical
- Email: oncall-team@example.com

**Warning (P2):**
- Slack: #alerts-warning
- Email: dev-team@example.com

**Info (P3):**
- Slack: #alerts-info

---

## Best Practices

### Query Optimization

1. **Use rate() for counters**: Always use `rate()` or `increase()` with counter metrics
2. **Specify time ranges**: Use appropriate time ranges (e.g., `[5m]` for recent trends)
3. **Aggregate wisely**: Use `sum`, `avg`, `max` appropriately to reduce cardinality
4. **Filter early**: Apply label filters before aggregation
5. **Avoid joins**: Prometheus doesn't handle joins well; denormalize if needed

### Recording Rules

For frequently-used complex queries, create recording rules:

```yaml
# Example recording rule
groups:
  - name: application_aggregates
    interval: 30s
    rules:
      - record: job:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (job)

      - record: job:http_request_duration:p95
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (job, le))
```

### Metric Naming Conventions

The application follows Prometheus naming conventions:
- **Counters**: `_total` suffix (e.g., `http_requests_total`)
- **Gauges**: Descriptive name (e.g., `resilience_utilization_rate`)
- **Histograms**: `_seconds`, `_bytes` units (e.g., `http_request_duration_seconds`)
- **Info**: `_info` suffix (e.g., `resilience_info`)

### Label Best Practices

1. **Low cardinality**: Keep label values bounded (avoid user IDs, timestamps)
2. **Meaningful names**: Use descriptive label names
3. **Consistent naming**: Use same label names across metrics
4. **Avoid high cardinality**: Don't use unbounded values as labels

---

## Troubleshooting

### Missing Metrics

**Problem:** Expected metrics not appearing in Prometheus

**Solutions:**
1. Check that backend is running: `curl http://localhost:8000/health`
2. Verify metrics endpoint: `curl http://localhost:8000/metrics`
3. Check Prometheus targets: http://localhost:9090/targets
4. Review Prometheus logs: `docker-compose -f monitoring/docker-compose.monitoring.yml logs prometheus`

### Incorrect Metric Values

**Problem:** Metrics showing unexpected values

**Solutions:**
1. Check metric type (counter vs gauge vs histogram)
2. Verify label filters in query
3. Check time range and aggregation
4. Review application logs for errors

### High Cardinality Issues

**Problem:** Too many unique label combinations

**Solutions:**
1. Remove unbounded labels (user IDs, etc.)
2. Aggregate labels at application level
3. Use recording rules to pre-aggregate
4. Increase Prometheus memory if needed

---

## Additional Resources

- [Prometheus Documentation](https://prometheus.io/docs/)
- [PromQL Tutorial](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Grafana Dashboards](https://grafana.com/docs/grafana/latest/dashboards/)
- [Alert Manager Configuration](https://prometheus.io/docs/alerting/latest/configuration/)
- [Monitoring README](../monitoring/README.md)
- [Alert Rules](../monitoring/prometheus/rules/)
