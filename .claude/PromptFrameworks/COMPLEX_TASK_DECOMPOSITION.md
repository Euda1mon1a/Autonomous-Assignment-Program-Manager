# Complex Task Decomposition Framework

> **Purpose:** Break down large, ambiguous, or multi-phase tasks into manageable pieces
> **Applies To:** Multi-day projects, features with unclear requirements, cross-system changes

---

## Overview

Complex tasks can be overwhelming and lead to **analysis paralysis** or **premature implementation**. This framework helps AI agents decompose large tasks into:

- **Atomic units** (single-responsibility tasks)
- **Dependency chains** (what must happen before what)
- **Parallel workstreams** (what can happen simultaneously)
- **Verification checkpoints** (how to know you're on track)

**Key Principle:** Break tasks down until each piece can be completed in **<2 hours** and verified independently.

---

## Phase 1: Task Analysis

Before decomposing, understand the task holistically.

### 1.1: Identify Task Type

| Task Type | Characteristics | Decomposition Strategy |
|-----------|-----------------|------------------------|
| **Feature** | Adds new capability | Layered (DB â†’ Service â†’ API â†’ UI) |
| **Bug Fix** | Fixes broken behavior | Root cause â†’ Fix â†’ Regression tests |
| **Refactor** | Improves structure | Extract â†’ Migrate â†’ Cleanup |
| **Migration** | Changes infrastructure | Backup â†’ Migrate â†’ Validate â†’ Rollback plan |
| **Integration** | Connects systems | Interface â†’ Adapter â†’ Tests â†’ Monitoring |

**Example:** "Implement N-1 contingency analysis"
- **Type:** Feature (new capability)
- **Strategy:** Layered decomposition

---

### 1.2: Define Boundaries

Answer these questions:

1. **What's in scope?**
   - What must be delivered?
   - What are the must-have features?

2. **What's out of scope?**
   - What can wait for later?
   - What are the nice-to-haves?

3. **What are the constraints?**
   - Time limits?
   - Compliance requirements (ACGME)?
   - Performance requirements?

4. **What are the unknowns?**
   - What needs research?
   - What assumptions need validation?

**Example: N-1 Contingency Analysis**

**In Scope:**
- Detect when loss of 1 person breaks coverage
- Calculate coverage metrics (% staffed)
- Flag N-1 violations in dashboard

**Out of Scope:**
- Auto-healing (generating replacement schedules)
- N-2 analysis (loss of 2 people)
- Historical trend analysis

**Constraints:**
- Must run in <5 seconds for 50-person schedule
- ACGME compliance must be maintained

**Unknowns:**
- Which algorithm? (Graph analysis? Brute force?)
- How to visualize results?

---

### 1.3: Identify Affected Systems

Map all systems touched by this task:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend                                                     â”‚
â”‚ - Dashboard widget (N-1 violations)                          â”‚
â”‚ - Schedule editor (warnings on N-1 risks)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend API                                                  â”‚
â”‚ - GET /resilience/n-minus-1                                  â”‚
â”‚ - POST /resilience/n-minus-1/analyze                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service Layer                                                â”‚
â”‚ - NMinusOneAnalyzer (NEW)                                    â”‚
â”‚ - CoverageCalculator (MODIFY)                                â”‚
â”‚ - ACGMEValidator (USE)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Database                                                     â”‚
â”‚ - resilience_metrics table (NEW)                             â”‚
â”‚ - assignments table (READ)                                   â”‚
â”‚ - persons table (READ)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Background Tasks                                             â”‚
â”‚ - Celery task: Nightly N-1 analysis                          â”‚
â”‚ - Alert: Send notification if violations found               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 2: Decomposition Strategies

### 2.1: Layered Decomposition (Bottom-Up)

For features that touch multiple architectural layers, decompose bottom-up:

```
Layer 1: Database
  â”œâ”€ Create migrations
  â””â”€ Define models

Layer 2: Service Logic
  â”œâ”€ Implement business logic
  â””â”€ Unit tests

Layer 3: API
  â”œâ”€ Define routes and schemas
  â””â”€ Integration tests

Layer 4: Frontend
  â”œâ”€ Build components
  â””â”€ Component tests

Layer 5: Integration
  â”œâ”€ End-to-end tests
  â””â”€ Documentation
```

**Example: N-1 Contingency Analysis**

```markdown
1. **Database Layer** (30 min)
   - Create `resilience_metrics` table
   - Migration: Add columns for N-1 data
   - Test: Migration up/down

2. **Service Layer** (3 hours)
   - Implement `NMinusOneAnalyzer.analyze()`
   - Algorithm: For each person, simulate removal â†’ check coverage
   - Unit tests: 10 test cases (happy path, edge cases)

3. **API Layer** (1 hour)
   - `GET /resilience/n-minus-1` (fetch latest results)
   - `POST /resilience/n-minus-1/analyze` (trigger analysis)
   - Integration tests: 5 scenarios

4. **Frontend Layer** (2 hours)
   - Dashboard widget showing N-1 violations
   - Color coding: GREEN (no violations), RED (violations)
   - Tests: Render tests + mock API

5. **Background Tasks** (1 hour)
   - Celery task: Nightly N-1 analysis
   - Alert: Email if violations found
   - Tests: Task execution + alerting

6. **Documentation** (30 min)
   - API docs
   - User guide: "Understanding N-1 Contingency"
```

**Total: ~8 hours, broken into 6 tasks (<2 hours each)**

---

### 2.2: Dependency Decomposition (Critical Path)

Identify dependencies and create a task graph:

```
Task Graph for N-1 Analysis:

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 1. DB Migration  â”‚ (BLOCKING)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 2. NMinusOneAnalyzer Service â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“                 â†“                  â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 3a. API Routes â”‚  â”‚ 3b. Unit Testsâ”‚  â”‚ 3c. Celery  â”‚ (PARALLEL)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                   â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 4. Frontend      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 5. E2E Tests     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 6. Documentation â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Path:** 1 â†’ 2 â†’ 3a â†’ 4 â†’ 5 â†’ 6

**Parallel Work:** Tasks 3a, 3b, 3c can run in parallel after Task 2

---

### 2.3: Vertical Slicing (End-to-End MVP)

For complex features, deliver a **minimal viable slice** first, then iterate:

**Slice 1 (MVP):** Basic N-1 detection for single day

```markdown
1. Service: Detect N-1 violations for single day
2. API: GET /resilience/n-minus-1/check?date=2024-01-15
3. Frontend: Simple table showing violations
4. Tests: Basic happy path

**Deliverable:** Users can check N-1 status for a specific day
```

**Slice 2:** Full week analysis

```markdown
1. Service: Extend to analyze full week
2. API: Add date range parameter
3. Frontend: Week view with violation counts
4. Tests: Multi-day scenarios

**Deliverable:** Users can analyze N-1 for a week
```

**Slice 3:** Automation and alerts

```markdown
1. Celery: Nightly analysis
2. Alerts: Email notifications
3. Dashboard: Real-time widget
4. Tests: Background task tests

**Deliverable:** Automated monitoring with proactive alerts
```

**Benefit:** Each slice is shippable and provides value incrementally.

---

### 2.4: Risk-First Decomposition

For high-risk tasks, tackle the **riskiest unknowns first**:

**Example:** "Integrate with external credentialing API"

**Risks:**
1. API may be unreliable (downtime)
2. API may have rate limits
3. Data format may not match our schema
4. Authentication may be complex

**Risk-First Task Order:**

```markdown
1. **Spike: Test API reliability** (2 hours)
   - Make test calls to API
   - Measure uptime, latency, error rates
   - **Decision:** Can we depend on this API?

2. **Spike: Understand rate limits** (1 hour)
   - Test rate limits
   - **Decision:** Do we need request throttling?

3. **Spike: Map data schemas** (1 hour)
   - Fetch sample data
   - Compare to our `Person` model
   - **Decision:** What transformations are needed?

4. **Implement adapter** (2 hours)
   - Only after risks are understood

5. **Add error handling** (1 hour)
   - Retry logic, circuit breaker

6. **Tests** (2 hours)
   - Mock API responses
   - Test error scenarios
```

**Benefit:** De-risk early, pivot if necessary.

---

## Phase 3: Parallel vs Sequential Execution

### 3.1: Identifying Parallel Tasks

Tasks can run in parallel if:

- âœ… No data dependencies (Task B doesn't need Task A's output)
- âœ… No ordering requirements (can be done in any order)
- âœ… Different files/systems (no merge conflicts)

**Example: Parallel Tasks for N-1 Analysis**

After implementing `NMinusOneAnalyzer` service, these can run in parallel:

```markdown
Team Member A (or Agent 1):
- Implement API endpoint
- Write integration tests
- Update API documentation

Team Member B (or Agent 2):
- Create Celery task
- Configure scheduling
- Write Celery tests

Team Member C (or Agent 3):
- Build frontend widget
- Add to dashboard
- Write component tests
```

**Coordination:** Each team member works on different files, no conflicts.

---

### 3.2: Identifying Sequential Tasks (Blocking)

Tasks must be sequential if:

- âŒ Data dependency (Task B needs Task A's output)
- âŒ Build dependency (Task B imports Task A's code)
- âŒ Testing dependency (Task B tests Task A's behavior)

**Example: Sequential Tasks for N-1 Analysis**

```markdown
1. Database migration (MUST BE FIRST)
   â†“
2. Service implementation (DEPENDS ON 1)
   â†“
3. API endpoint (DEPENDS ON 2)
   â†“
4. Frontend widget (DEPENDS ON 3)
```

You **cannot** build the frontend widget before the API endpoint exists.

---

### 3.3: Using TodoWrite for Task Tracking

For complex tasks, use `TodoWrite` to track parallel and sequential work:

```markdown
todos:
  - content: "Create database migration for resilience_metrics"
    status: "completed"
    activeForm: "Creating database migration"

  - content: "Implement NMinusOneAnalyzer.analyze() service method"
    status: "completed"
    activeForm: "Implementing NMinusOneAnalyzer service"

  # These three can run in parallel
  - content: "Create API endpoint GET /resilience/n-minus-1"
    status: "in_progress"
    activeForm: "Creating API endpoint"

  - content: "Write unit tests for NMinusOneAnalyzer (12 test cases)"
    status: "pending"
    activeForm: "Writing unit tests"

  - content: "Create Celery task for nightly N-1 analysis"
    status: "pending"
    activeForm: "Creating Celery task"

  # Frontend depends on API being done
  - content: "Build dashboard widget for N-1 violations"
    status: "pending"
    activeForm: "Building dashboard widget"
```

---

## Phase 4: Checkpoint Creation

Checkpoints are **verification points** where you confirm progress before continuing.

### 4.1: Types of Checkpoints

| Checkpoint Type | Purpose | How to Verify |
|-----------------|---------|---------------|
| **Compilation** | Code compiles/runs | `pytest` or `npm run build` |
| **Test** | Functionality works | Unit/integration tests pass |
| **Integration** | Components connect | E2E tests pass |
| **Performance** | Meets speed requirements | Load tests, profiling |
| **Compliance** | Meets regulatory requirements | ACGME validation tests |
| **Review** | Code quality acceptable | Self-review, linter, skill review |

### 4.2: Checkpoint Placement

Place checkpoints at:

1. **After each layer** (DB â†’ Service â†’ API â†’ UI)
2. **Before merging** (all tests pass, docs updated)
3. **After risky tasks** (external API integration, algorithm change)
4. **Before destructive operations** (database migration, schedule regeneration)

**Example: Checkpoints for N-1 Analysis**

```markdown
Checkpoint 1: After Database Migration
- âœ… Migration runs successfully
- âœ… Migration rollback works
- âœ… No data loss in test database

Checkpoint 2: After Service Implementation
- âœ… Unit tests pass (12/12)
- âœ… Algorithm correctly identifies N-1 violations
- âœ… Performance: Analyzes 50-person schedule in <5 seconds

Checkpoint 3: After API Implementation
- âœ… Integration tests pass (5/5)
- âœ… API returns correct data format
- âœ… Error handling works (404, 500 scenarios)

Checkpoint 4: After Frontend Implementation
- âœ… Component tests pass
- âœ… Widget displays correctly in dashboard
- âœ… Color coding (GREEN/RED) works

Checkpoint 5: Before Merging
- âœ… All tests pass (unit + integration + E2E)
- âœ… Linter warnings fixed
- âœ… Documentation updated
- âœ… Code reviewed (self or peer)
- âœ… CHANGELOG.md updated
```

### 4.3: Checkpoint Automation

Automate checkpoints with scripts:

```bash
#!/bin/bash
# scripts/checkpoint.sh - Run before committing

echo "ðŸ” Running checkpoint verification..."

# 1. Tests
echo "âœ… Running tests..."
cd backend && pytest || exit 1

# 2. Linting
echo "âœ… Running linter..."
ruff check . || exit 1

# 3. Type checking
echo "âœ… Type checking..."
cd ../frontend && npm run type-check || exit 1

# 4. ACGME compliance
echo "âœ… ACGME compliance..."
cd ../backend && pytest -m acgme || exit 1

echo "âœ… All checkpoints passed!"
```

Usage:

```bash
./scripts/checkpoint.sh
# If passes, safe to commit
# If fails, fix issues before committing
```

---

## Phase 5: Handling Ambiguity

Complex tasks often have **unclear requirements**. Use these strategies:

### 5.1: Spike Solutions (Time-Boxed Research)

When requirements are unclear, do a **spike** (time-boxed investigation):

```markdown
## Spike: Determine best algorithm for N-1 analysis

**Time Box:** 2 hours

**Questions to Answer:**
1. What algorithms exist for this problem?
2. What are the trade-offs (speed, accuracy, complexity)?
3. Which algorithm fits our constraints (<5 seconds for 50 people)?

**Approach:**
- Research graph algorithms (NetworkX)
- Prototype 2-3 approaches
- Benchmark with sample data

**Deliverable:**
- Decision document: "We should use X algorithm because Y"
- Prototype code (throwaway, not production)

**Outcome:**
- If successful: Proceed with chosen algorithm
- If unsuccessful: Extend spike by 1 hour or escalate to human
```

### 5.2: Progressive Refinement

If requirements are vague, start broad and narrow down:

**Iteration 1: Proof of Concept**
- Simplest possible implementation
- No error handling, no optimization
- **Goal:** Does this approach work at all?

**Iteration 2: Happy Path**
- Implement core functionality
- Basic error handling
- **Goal:** Can users complete the main task?

**Iteration 3: Edge Cases**
- Handle errors, edge cases
- Optimize performance
- **Goal:** Production-ready

**Iteration 4: Polish**
- Better UX, documentation
- Advanced features
- **Goal:** Delightful experience

### 5.3: Decision Trees for Ambiguity

When faced with ambiguous choices, create decision trees:

```
Should we support cross-rotation swaps?
â”œâ”€ YES
â”‚  â”œâ”€ Pros: More flexibility, happier users
â”‚  â”œâ”€ Cons: More complex validation, ACGME risk
â”‚  â””â”€ Decision: Only if ACGME validator can handle it
â”‚
â””â”€ NO
   â”œâ”€ Pros: Simpler code, lower risk
   â”œâ”€ Cons: Less flexible for users
   â””â”€ Decision: Start with NO, add later if requested
```

**Document the decision** in code or ADR:

```python
# backend/app/services/swap_executor.py

# Decision: Do not support cross-rotation swaps in v1
# Reason: ACGME validation complexity too high for initial release
# Future: Can add in v2 if users request it
ALLOW_CROSS_ROTATION_SWAPS = False
```

---

## Example: Full Decomposition for "Implement Schedule Optimizer"

### Task Analysis

**Type:** Feature (new capability)

**In Scope:**
- Optimize existing schedules to reduce 80-hour violations
- Use OR-Tools constraint solver
- Preserve as many existing assignments as possible

**Out of Scope:**
- Generating schedules from scratch
- Multi-objective optimization (just minimize violations)

**Constraints:**
- Must maintain ACGME compliance
- Must run in <2 minutes for 50-person schedule

**Unknowns:**
- Which solver algorithm? (CP-SAT, GLOP, SCIP?)
- How to model constraints in OR-Tools?

---

### Task Breakdown

```markdown
## Phase 1: Research & Spike (4 hours)

### Spike 1: OR-Tools Algorithm Selection (2 hours)
- Research CP-SAT, GLOP, SCIP solvers
- Prototype simple schedule optimization
- Benchmark: Which is fastest?
- **Checkpoint:** Decision doc on algorithm choice

### Spike 2: Constraint Modeling (2 hours)
- Model 80-hour rule as constraint
- Model supervision ratios as constraint
- Test with sample data
- **Checkpoint:** Validated constraint model

---

## Phase 2: Database Layer (1 hour)

### Task 2.1: Create `optimizer_runs` table (30 min)
- Migration: Add table for optimization run history
- Columns: id, started_at, completed_at, violations_before, violations_after

### Task 2.2: Test migration (30 min)
- Test up/down migrations
- **Checkpoint:** Migration works

---

## Phase 3: Service Layer (6 hours)

### Task 3.1: Implement `ScheduleOptimizer.optimize()` (3 hours)
- Load existing assignments
- Model constraints in OR-Tools
- Run solver
- Return optimized assignments

### Task 3.2: Write unit tests (2 hours)
- Happy path: Optimization reduces violations
- Edge case: No violations to optimize
- Edge case: Unsolvable (no valid solution)
- **Checkpoint:** 10/10 tests passing

### Task 3.3: Add ACGME validation (1 hour)
- Validate optimized schedule maintains compliance
- Rollback if validation fails
- **Checkpoint:** All optimized schedules pass ACGME validation

---

## Phase 4: API Layer (2 hours)

### Task 4.1: Create `POST /schedules/{id}/optimize` endpoint (1 hour)
- Request: `OptimizeRequest(preserve_existing=True)`
- Response: `OptimizeResponse(violations_reduced=5)`

### Task 4.2: Integration tests (1 hour)
- Test: Successful optimization
- Test: No changes needed (already optimal)
- Test: Optimization timeout
- **Checkpoint:** 5/5 integration tests passing

---

## Phase 5: Frontend (3 hours)

### Task 5.1: Add "Optimize" button to schedule editor (1 hour)
- Button triggers API call
- Show loading state during optimization

### Task 5.2: Display optimization results (1 hour)
- Show: "Reduced violations from 8 to 3"
- Allow user to accept or reject changes

### Task 5.3: Component tests (1 hour)
- Test button click
- Test loading state
- Test result display
- **Checkpoint:** Component tests passing

---

## Phase 6: Background Tasks (2 hours)

### Task 6.1: Create Celery task for scheduled optimization (1 hour)
- Weekly task: Optimize all schedules
- Email results to admin

### Task 6.2: Celery tests (1 hour)
- Test task execution
- Test email sending
- **Checkpoint:** Celery tests passing

---

## Phase 7: Documentation (1 hour)

### Task 7.1: Update API docs (30 min)
- Document `/schedules/{id}/optimize` endpoint

### Task 7.2: Update user guide (30 min)
- "How to Optimize Your Schedule" section
- **Checkpoint:** Docs reviewed and accurate

---

## Total Estimated Time: 19 hours
```

---

### Dependency Graph

```
Spike 1 & 2 (PARALLEL)
    â†“
Database Migration
    â†“
ScheduleOptimizer Service
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“             â†“
API Endpoint   Celery Task   Unit Tests (PARALLEL)
    â†“             â†“
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Frontend Component
           â†“
    Documentation
```

---

## Summary: Decomposition Checklist

Before starting a complex task:

- [ ] **Analyze task type** (feature, bug, refactor, migration)
- [ ] **Define scope** (what's in, what's out, constraints, unknowns)
- [ ] **Identify affected systems** (DB, service, API, frontend, background)
- [ ] **Choose decomposition strategy** (layered, dependency, vertical slice, risk-first)
- [ ] **Break into <2-hour tasks**
- [ ] **Map dependencies** (what blocks what)
- [ ] **Identify parallel work** (what can run concurrently)
- [ ] **Place checkpoints** (how to verify progress)
- [ ] **Handle ambiguity** (spikes, progressive refinement, decision trees)
- [ ] **Track with TodoWrite** (if multi-phase project)

---

**Remember:** The goal of decomposition is to **reduce cognitive load** and make progress **verifiable at every step**. Break it down, execute incrementally, verify continuously.
