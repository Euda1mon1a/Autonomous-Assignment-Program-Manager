
# Production Docker Compose Configuration
# Usage: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
#
# This file extends docker-compose.yml with production-specific settings:
# - Resource limits (CPU, memory)
# - Restart policies
# - Production logging
# - Volume persistence
# - Network optimizations

services:
  # PostgreSQL Database - Production Settings
  db:
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    volumes:
      # Persistent data storage
      - postgres_data:/var/lib/postgresql/data
      # Backup mount point (optional)
      - ./backups/postgres:/backups

  # Redis - Production Settings
  redis:
    restart: always
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
      --tcp-backlog 511
      --timeout 300
      --tcp-keepalive 60
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 768M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
        compress: "true"
    volumes:
      - redis_data:/data
      - ./backups/redis:/backups
    # Production health check - strict Redis availability monitoring
    # Fails fast with minimal retries for production alerting
    # Interval kept short for rapid failure detection
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # FastAPI Backend - Production Settings
  backend:
    restart: always
    environment:
      DEBUG: "false"
      LOG_LEVEL: "info"
      WORKERS: "4"
      CORS_ORIGINS: ${CORS_ORIGINS}
      TRUSTED_HOSTS: ${TRUSTED_HOSTS:-["*"]}
      RATE_LIMIT_ENABLED: "true"
      RATE_LIMIT_PER_MINUTE: "60"
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/0
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        compress: "true"
    # Production health check - uses curl for robust HTTP checking
    # Extended start period accounts for migration and warmup time
    # Fails on non-200 responses for strict production monitoring
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Celery Worker - Production Settings
  celery-worker:
    restart: always
    environment:
      LOG_LEVEL: "info"
      CELERY_WORKER_CONCURRENCY: "8"
      CELERY_WORKER_PREFETCH_MULTIPLIER: "1"
      CELERY_WORKER_MAX_TASKS_PER_CHILD: "1000"
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/0
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 3G
        reservations:
          cpus: '2.0'
          memory: 2G
      # Note: Using high concurrency (8) instead of multiple replicas
      # to avoid container_name conflict. For horizontal scaling,
      # remove container_name from docker-compose.yml and add replicas here.
    logging:
      driver: "json-file"
      options:
        max-size: "15m"
        max-file: "5"
        compress: "true"
    command: >
      celery -A app.core.celery_app worker
      --loglevel=info
      -Q default,resilience,notifications
      --concurrency=8
      --max-tasks-per-child=1000
      --time-limit=600
      --soft-time-limit=540

  # Celery Beat - Production Settings
  celery-beat:
    restart: always
    environment:
      LOG_LEVEL: "info"
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/0
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
        compress: "true"
    volumes:
      # Persistent beat schedule
      - celery_beat:/var/lib/celery

  # Next.js Frontend - Production Settings
  frontend:
    restart: always
    environment:
      NODE_ENV: "production"
      NEXT_TELEMETRY_DISABLED: "1"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"
    # Production health check - ensures Next.js is serving requests
    # Extended start period for build and initialization
    # Uses curl for production-grade HTTP validation
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # MCP Server - Production Settings
  # Model Context Protocol for AI Assistant Integration
  # Provides 29+ specialized scheduling tools for Claude Code and other AI agents
  mcp-server:
    restart: always
    environment:
      # Transport mode - HTTP for Docker container compatibility
      # HTTP enables parallel MCP connections while maintaining security via localhost binding
      MCP_TRANSPORT: http
      MCP_HOST: "0.0.0.0"
      MCP_PORT: "8080"
      # API Integration - connects to FastAPI backend via internal network
      API_BASE_URL: http://backend:8000
      API_USERNAME: ${API_USERNAME}
      API_PASSWORD: ${API_PASSWORD}
      # Celery for async task management
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/0
      # Production logging - reduced verbosity for performance
      LOG_LEVEL: WARNING
      # Python path for imports
      PYTHONPATH: /app/src
    # Port exposed on localhost only for security
    # Enables AI agent access while preventing network exposure
    # Inherited security_opt (no-new-privileges) from base config
    ports:
      - "127.0.0.1:8080:8080"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"
    # Production health check - validates MCP server initialization
    # Python import test ensures module dependencies are available
    # Short start period since MCP has minimal dependencies
    healthcheck:
      test: ["CMD", "python", "-c", "from scheduler_mcp.server import mcp; print('healthy')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Nginx Reverse Proxy (Production)
  nginx:
    image: nginx:alpine
    container_name: residency-scheduler-nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - backend
      - frontend
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        compress: "true"
    # Production health check - validates nginx reverse proxy
    # Checks /health endpoint routing to backend service
    # Uses wget for minimal Alpine image compatibility
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:80/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/redis
  celery_beat:
    driver: local
  nginx_logs:
    driver: local

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
